# ═══════════════════════════════════════════════════════════════════
# P302 SLFB 鋅空氣電池 ── 正式模擬訓練配置 v7 (TOU Arbitrage)
# 架構: CORAL 三層式安全 RL（CRTSN + OCC + Adaptive Loop）
# ─────────────────────────────────────────────────────────────────
# v7 修正（重大）：
#   - 導入 2026 台電夏月 TOU 真實費率（尖峰 7.13/半尖峰 4.69/離峰 2.06 TWD/kWh）
#   - 週末全日 2.06 TWD（無套利空間 → 鼓勵待機）
#   - Reward 完全重寫：
#     · 核心 = (Baseline_Cost - Agent_Cost) × tou_reward_scale（經濟信號放大）
#     · 尖峰 16-22 放電 → +1.0 bonus / 充電 → -1.0 penalty
#     · 離峰 00-09 充電 → +0.5 bonus
#     · 週末充放電 → -0.5 penalty (SoH 保護)
#     · 移除 SoC centering / action efficiency (消除 Lazy Agent)
#   - 4 Scenario 能流情況碼 (1=Battery Solo, 2=Grid Support, 3=Grid Charge, 4=Standby)
#   - 沿用 v6 正確能流模型（PV→Load 優先、Grid 單向）
# ═══════════════════════════════════════════════════════════════════

random_seed: 42

device: "auto"   # auto / cpu / cuda

# ── 環境參數（與 P302 實體規格一致）────────────────────────────────
env:
  microgrid_id: 0
  # 576 步 = 6天 × 96步/天（15分鐘一步），與 training CSV 筆數一致
  episode_length: 576
  time_step: 0.25               # 15分鐘 = 0.25小時

  # P302 SLFB 電池規格
  # 10 mAh @ ~7V nominal ≈ 0.07 Wh = 0.00007 kWh
  battery_capacity_kwh: 0.00007
  # 最大功率 20mA × 8.5V = 170mW ≈ 0.00017 kW
  battery_power_kw: 0.00017
  battery_efficiency: 0.95       # 功率損耗 5%（不加噪音/lag 等 sim-to-real 設定）

  use_real_data: true
  # 使用處理好的 6 天 15 分鐘 CSV（相對於 core/ 目錄）
  dataset_csv_path: "../data/processed/training_7day_15min.csv"
  dataset_pv_join_wind: false

  # CSV 欄位映射
  dataset_time_column: "timestamp"

  # P302 市電單向：可買不可逆送
  # PV→負載優先，市電補足剩餘負載+充電池，電池放電減少市電依賴
  allow_grid_trading: false

  # 無 ramp limit（電池功率已很小，且不用 sim-to-real 噪音）
  ramp_limit_kw: null
  hard_guard: false

  # ── TOU Reward Scale（關鍵參數）─────────────────────────────────
  # 因為 P302 電池極小（0.07 Wh），絕對套利利潤在微元級。
  # 必須乘以大倍率讓 NN 梯度可學習。
  # 計算：max savings/step = 0.00017kW × 0.25h × 7.13TWD = 0.000303 TWD
  # 3000 × 0.000303 ≈ 0.91 → 單步 reward ≈ [-1, +1] ✓
  tou_reward_scale: 3000

  # ── Flow Rate 電化學等效模型（SLFB 鋅空氣電池）────────────────────
  # 啟用 2D action space: [power_kw, flow_fraction]
  use_flow_rate_action: true
  # 基線內阻 R_base = (V_charge - V_discharge) / (2 × I_rated)
  # = (8.5 - 5.6) / (2 × 0.02) = 72.5 Ω
  flow_R_base_ohm: 72.5
  # 幫浦最大寄生功率 ≈ 16.8 mW = 0.0168 W
  flow_P_max_pump_W: 0.0168
  # 內阻增幅因子（低流速 → 濃度極化 → 內阻飆升）
  flow_k_R: 0.5
  # 開路電壓
  flow_V_OCV_charge: 8.5
  flow_V_OCV_discharge: 5.6
  # 額定電流
  flow_I_rated_A: 0.020

  # ── 擴充觀察空間 ────────────────────────────────────────────
  # 暫時關閉（SoH 資料在正式實驗前不夠精確）
  use_extended_obs: false

# ── SAC 超參數 ──────────────────────────────────────────────────
sac:
  actor_lr: 0.0003
  critic_lr: 0.0003
  gamma: 0.99
  tau: 0.005
  alpha: 0.05                   # 初始熵溫度（低，鼓勵早期收斂）
  target_entropy: -2.0          # 標準值 = -action_dim
  alpha_lr: 0.0001              # alpha 獨立 lr（比 actor 3e-4 低，緩慢調整）
  hidden_dim: 128               # P302 任務不需太大網路
  buffer_size: 100000
  batch_size: 256
  warmup_steps: 2000            # 用隨機策略先填滿 buffer
  update_every: 4               # 每 4 步更新一次

# ── 訓練設定 ────────────────────────────────────────────────────
training:
  total_episodes: 2000          # 2000 集（每集 576 步 = ~115萬步總量）
  max_steps: 576                # 與 episode_length 一致
  eval_every: 25                # 每 25 集評估一次（更頻繁看進度）
  eval_episodes: 3              # 評估時跑 3 集取平均
  save_every: 100               # 每 100 集存 checkpoint

  # ★ v5: CORAL Curriculum 訓練
  # Phase 1 (EP 0~299): 純 SAC — agent 先學基本 TOU 套利
  # Phase 2 (EP 300~1999): SAC + CRTSN + OCC + Adaptive — 三層全開
  variant: "sac_sn"
  safetynet_warmup_episodes: 300

  # Evidential 超參（variant=sac_sn_evi 時使用）
  lambda_evi: 0.001
  beta_risk: 0.5

# ── SafetyNet（Phase 2 啟用）──────────────────────────────────
safetynet:
  ramp_limit_kw: null           # 不限制 ramp（電池功率極小）

# ── Conformal Prediction ────────────────────────────────────────
conformal:
  window: 2880                  # 殘差窗口大小（≈5集的步數）
  delta: 0.1                    # 初始覆蓋率 = 1 - delta = 90%

# ── Reward 調整 ─────────────────────────────────────────────
reward:
  # Phase 1: 這些 penalty 不生效（SafetyNet OFF）
  # Phase 2: SafetyNet ON 時啟動
  realized_violation_penalty: 10.0
  attempted_violation_penalty: 0.01
  safety_projection_penalty: 0.0005

# ── Stress Testing（不使用）──────────────────────────────────
stress:
  enable: false

# ── 日誌與輸出 ───────────────────────────────────────────────
logging:
  log_interval: 10              # 每 10 集列印進度摘要
  save_models: true
  save_metrics: true
  plot_results: true
  csv_per_episode: true         # 每集寫一行 CSV（即時追蹤）
